<!DOCTYPE html>
<html lang="ja">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<title>Twitter</title>
<link rel="stylesheet" href="style.css">
<link rel="license" href="http://creativecommons.org/licenses/by/4.0/">
</head>
<body>

<nav id="breadcrumbs">
<a href="/~okumura/">ホーム</a> &gt;
<a href="./">Python</a> &gt;
</nav>

<h1>Twitter</h1>

<p>Twitter を Python から使うライブラリは <a href="https://developer.twitter.com/en/docs/developer-utilities/twitter-libraries.html">Twitter libraries</a> の Python の項にいくつかリストされている。どれがいいかわからないが，とりあえず一番上の <a href="https://github.com/bear/python-twitter/">python-twitter</a> を試してみる（そのうち <a href="https://github.com/geduldig/TwitterAPI">TwitterAPI</a> か <a href="https://pypi.org/project/tweepy/">tweepy</a> か <a href="https://github.com/ryanmcgrath/twython">twython</a> も試してみよう）。インストールは</p>

<pre>
<code>pip install python-twitter
</code></pre>

<p>でできる。</p>

<p>まずは Twitter のアプリケーション登録をする。方法は <a href="https://python-twitter.readthedocs.io/en/latest/">python-twitter's documentation</a> にも書かれているし，日本語の解説もたくさんある（例えば <a href="https://cre8cre8.com/python/twitter-api.htm">Python3でTwitterAPIを使う方法をどのサイトよりも丁寧に解説する</a> の前半）。</p>

<p>登録をしたら，Consumer Key，Consumer Secret，Access Token，Access Token Secret がもらえる。これらを次のコードの <code>...</code> の部分にコピペする。</p>

<p>試してみよう：</p>

<pre>
<code>import twitter

api = twitter.Api(consumer_key='...',
                  consumer_secret='...',
                  access_token_key='...',
                  access_token_secret='...',
                  tweet_mode='extended',
                  sleep_on_rate_limit=True)

api.VerifyCredentials() # 自分が正しく認識できているかチェック

home = api.GetHomeTimeline() # ホームタイムラインを取得（デフォルト20件）
</code></pre>

<p>これで <code>home</code> を表示すればだいたいの感じがわかる。このクラスの詳細は <code>??twitter.models.Status</code> と打ち込めば出てくる。この中の必要な項目を自分好みに出力すればよい。簡単な例を挙げておく：</p>

<pre>
<code>for t in home:
    if (t.retweeted_status):
        t = t.retweeted_status
    for u in t.urls:
        t.full_text = t.full_text.replace(u.url, u.expanded_url)
    print(t.id, t.created_at, t.user.screen_name, t.full_text)
</code></pre>

<p>これを少しいじれば，自家製Twitterクライアントができる。これ以外に，位置情報 <code>t.place</code>，正確な位置情報 <code>t.geo</code> などが得られる。普段はEmacsのtwittering-modeを使っているが，自動処理にはコマンドラインで使えるほうが便利だ。</p>

<p>書き込みはこんな感じ（通常はツイート本文だけでよい）：</p>

<pre>
<code>api.PostUpdate("テスト",  # ツイート本文（これだけ必須）
               media="hoge.jpg",  # 添付画像ファイル（複数あればリスト）
               in_reply_to_status_id=1140050903828819970, # リプライ先のツイートID
               auto_populate_reply_metadata=True, # リプライ先の @... を自動挿入
               attachment_url="https://twitter.com/.../status/...", # 引用リツイート
               latitude=34.7468, longitude=136.5248, # 位置情報
               display_coordinates=True) # 正確な位置情報にするか
</code></pre>

<p>引用リツイートは従来のようにツイート本文末尾にURLを書いてもいいが，<code>attachment_url="..."</code> で指定すると文字数カウントに入らない。リプライの先頭に付ける <code>@...</code> も，手で書く代わりに <code>auto_populate_reply_metadata=True</code> にすれば自動で入り，文字数カウントに入らない。</p>

<p><code>r = api.PostUpdate(...)</code> のように戻り値を取得すれば，例えば <code>r.id</code> でツイートのIDが調べられる。ツイートをつなげていくときに便利。</p>

<hr>

<p>毎時cronで起動して日毎のホームタイムラインをファイルにするコード例：</p>

<pre>
<code>#! /usr/local/bin/python3

import twitter
import time
from dateutil.parser import parse
from pytz import timezone

api = twitter.Api(consumer_key='...',
                  consumer_secret='...',
                  access_token_key='...',
                  access_token_secret='...',
                  tweet_mode='extended',
                  sleep_on_rate_limit=True)

try:
    with open("maxid") as f:
        sid = int(f.read())
except:
    sid = 1

home = []
mid = None
while True:
    h = api.GetHomeTimeline(count=200, since_id=sid, max_id=mid)
    home.extend(h)
    if len(h) &lt; 150:
        break
    mid = home[-1].id - 1

if not home:
    exit()

with open("maxid", "w") as f:
    f.write(str(home[0].id))

home.reverse()

with open(time.strftime("%Y%m%d"), "a", newline="\n") as f:
    for t in home:
        if (t.retweeted_status):
            t = t.retweeted_status
        s = t.full_text
        for u in t.urls:
            s = s.replace(u.url, u.expanded_url)
        c = parse(t.created_at).astimezone(timezone('Asia/Tokyo')).strftime("%Y-%m-%d %H:%M:%S")
        print(t.id, c, t.user.screen_name, s.replace("\n", "\r"), sep="\t", file=f)
</code></pre>

<p>grepしやすいように1ツイート1行にするために，ツイート中の改行は <code>"\r"</code> に変換している。</p>

<p>稀に <code>h = api.GetHomeTimeline(...)</code> が失敗することがある。ゆっくり何度かやれば成功するみたいなので，この行を次で置き換えてみた：</p>

<pre>
<code>    cnt = 0
    while cnt < 5:
        time.sleep(30)
        try:
            h = api.GetHomeTimeline(count=200, since_id=sid, max_id=mid)
            cnt = 10
        except:
            h = []
            cnt += 1
</code></pre>

<hr>

<p>検索は python-twitter の<a href="https://python-twitter.readthedocs.io/en/latest/searching.html">ドキュメント</a>や，Twitter API の <a href="https://developer.twitter.com/en/docs/tweets/search/api-reference/get-search-tweets">Search Tweets</a>，<a href="https://developer.twitter.com/en/docs/tweets/search/guides">Search Tweet Guides</a> 参照。例：</p>

<pre>
<code>import urllib.parse

query = {"q": "ほげ ふが",        # 検索文字列（スペース区切り）
         "result_type": "recent", # 新しいもの順に取得
         "count": 100}            # 最大100

results = []
while True:
    r = api.GetSearch(raw_query=urllib.parse.urlencode(query))
    print('Retrieved', len(r), 'tweets')
    if len(r) == 0:
        break
    results.extend(r)
    query['max_id'] = results[-1].id - 1
    time.sleep(1)
</code></pre>

<p>この方法で取得できるものは，検索語によっては，大部分が重複（リツイート）である。</p>

<p>結果をMeCabで形態素解析し，名詞の出現頻度をグラフにしてみよう：</p>

<pre>
<code>import MeCab
import collections

text = ""
for t in results:
    if (t.retweeted_status):
        t = t.retweeted_status
    s = t.full_text
    for u in t.urls:
        s = s.replace(u.url, ' ')
    text += s + '\n'

mecab = MeCab.Tagger()
nodes = mecab.parseToNode(text)
s = []
while nodes:
    if nodes.feature[:2] == '名詞':
        s.append(nodes.surface)
    nodes = nodes.next

c = collections.Counter(s)

stopwords={"こと","もの","さん","それ","たち","よう","そう",
           "ため","これ","どこ","ほう","とき","みたい","そこ",
           "of","the","RT","うち","あと","こちら","あたり","あら",
           "ところ","わけ","はず","たくさん","ほんと","すべて",
           "ツイッター","Twitter"}

i = 0
mc = {}
for k,v in c.most_common():
    if len(k) > 1 and k not in stopwords:
        print(k, v)
        mc[k] = v
        i += 1
        if i >= 30:
            break

plt.figure(figsize=[5, 5])
plt.barh(range(len(mc),0,-1), mc.values())
plt.yticks(range(len(mc),0,-1), mc.keys())
plt.savefig('hist.png', bbox_inches="tight")
</code></pre>

<hr>

<p><a href="../" rel="author">奥村 晴彦</a></p>

<p>
<!-- hhmts start -->
Last modified: <time>2021-04-12 20:09:33</time>
<!-- hhmts end -->
</p>
</body>
</html>
