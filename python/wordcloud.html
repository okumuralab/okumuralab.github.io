<!DOCTYPE html>
<html lang="ja">
<head>
<link rel="canonical" href="https://okumuralab.org/~okumura/python/wordcloud.html">
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>ワードクラウド</title>
<link rel="stylesheet" href="style.css">
<link rel="license" href="https://creativecommons.org/licenses/by/4.0/">
<script src="../js/copypre.js"></script>
</head>
<body>

<nav id="breadcrumbs">
<a href="../">ホーム</a> &gt;
<a href="./">Python</a> &gt;
</nav>

<h1>ワードクラウド</h1>

<h2>はじめに</h2>

<p>ワードクラウド（word cloud）とは頻出語を頻度に比例する大きさで雲のように並べたものです。</p>

<p>英語のワードクラウドは wordcloud ライブラリで簡単に描けます。あらかじめ <code>pip install wordcloud</code> などとしてインストールしておきます。テキストとしては何でもいいのですが、ここでは <code>WordCloud()</code> の説明文（docstring）を用いてみます：</p>

<pre>
from wordcloud import WordCloud

text = WordCloud.__doc__
wc = WordCloud(width=480, height=320)
wc.generate(text)
wc.to_file('wc1.png')
</pre>

<figure><img src="img/wc1.png" alt="WordCloudの説明のワードクラウド"></figure>

<p>日本語はこのように簡単にはいきません。まずは単語に分解しなければなりません（形態素解析）。そのためのツールとして、昔から有名な<a href="https://taku910.github.io/mecab/">MeCab</a>（めかぶ、和布蕪）、Python だけで実装した <a href="https://mocobeta.github.io/janome/">Janome</a>（じゃのめ、蛇の目）、新しめの <a href="https://github.com/WorksApplications/Sudachi">Sudachi</a>（Python版 <a href="https://github.com/WorksApplications/SudachiPy">SudachiPy</a>）などがあります。</p>

<h2>MeCabを使う</h2>

<p>まず MeCab と辞書をインストールします。Windows では <a href="https://github.com/ikegami-yukino/mecab/releases">MeCab 64bit version</a> でうまくいきました。インストールの際に文字コードを求められますので、必ず UTF-8 を選びます。Mac では Homebrew でインストールするのが簡単です（<code>brew install mecab mecab-ipadic</code>）。強化された辞書 <a href="https://github.com/neologd/mecab-ipadic-neologd">mecab-ipadic-NEologd</a> もあります。</p>

<p>さらに、MeCab を Python から使うためのライブラリもインストールします。</p>

<pre>
pip install mecab-python3
</pre>

<p>動作確認してみましょう：</p>

<pre class="cell">
import MeCab

mecab = MeCab.Tagger()
print(mecab.parse("すもももももももものうち"))
</pre>

<pre>
すもも  名詞,一般,*,*,*,*,すもも,スモモ,スモモ
も      助詞,係助詞,*,*,*,*,も,モ,モ
もも    名詞,一般,*,*,*,*,もも,モモ,モモ
も      助詞,係助詞,*,*,*,*,も,モ,モ
もも    名詞,一般,*,*,*,*,もも,モモ,モモ
の      助詞,連体化,*,*,*,*,の,ノ,ノ
うち    名詞,非自立,副詞可能,*,*,*,うち,ウチ,ウチ
EOS
</pre>

<pre class="cell">
chasen = MeCab.Tagger("-Ochasen")
print(chasen.parse("すもももももももものうち"))
</pre>

<pre>
すもも  スモモ  すもも  名詞-一般               
も      モ      も      助詞-係助詞             
もも    モモ    もも    名詞-一般               
も      モ      も      助詞-係助詞             
もも    モモ    もも    名詞-一般               
の      ノ      の      助詞-連体化             
うち    ウチ    うち    名詞-非自立-副詞可能            
EOS
</pre>

<pre class="cell">
wakati = MeCab.Tagger("-Owakati")
print(wakati.parse("すもももももももものうち"))
</pre>

<pre>
すもも も もも も もも の うち 
</pre>

<p>とりあえず最後の例のようにして分かち書きにすればワードクラウドが作れそうです。</p>

<p>サンプルとして、寺田寅彦の<a href="https://www.aozora.gr.jp/cards/000042/files/43260_17028.html">流言蜚語</a>を題材としてみます。青空文庫のサイトからコピペしてください。改行を含む長い文章ですので、全体を <code>"""..."""</code> で囲みます。</p>

<pre class="cell">
text = """
長い管の中へ、水素と酸素とを適当な割合に混合したものを入れておく、
（中略）
甚だしい恥辱を曝さらす事なくて済みはしないかと思われるのである。
"""
words = wakati.parse(text)
wc = WordCloud(width=480, height=320, background_color="white",
               font_path="/System/Library/Fonts/ヒラギノ角ゴシック W6.ttc")
wc.generate(words)
wc.to_file('wc2.png')
</pre>

<p>Windows では <code>font_path</code> は例えば <code>"C:/WINDOWS/Fonts/meiryob.ttc"</code> などとします。</p>

<figure><img src="img/wc2.png" alt="流言蜚語ワードクラウド"></figure>

<p>「その」「ある」などのあまり意味のないことばが大きく出てしまいました。これらの単語は「ストップワード」として外してしまいましょう。そのためには <code>WordCloud()</code> に例えば <code>stopwords={"その","ある"}</code> のようなオプション引数を与えます。</p>

<p>もっと楽に済ませるには、せっかく MeCab で品詞がわかるのですから、名詞だけにしてしまうという手もあります：</p>

<pre class="cell">
nodes = mecab.parseToNode(text)
s = []
while nodes:
    if nodes.feature[:2] == '名詞':
        s.append(nodes.surface)
    nodes = nodes.next
wc = WordCloud(width=480, height=320, background_color="white",
               stopwords={"もの","これ","ため","それ","ところ","よう"},
               font_path="/System/Library/Fonts/ヒラギノ角ゴシック W6.ttc")
wc.generate(" ".join(s))
wc.to_file('wc3.png')
</pre>

<figure><img src="img/wc3.png" alt="流言蜚語ワードクラウド"></figure>

<p>ちなみに、プログラム中にテキストを書き込むのは面倒なので、テキストは別ファイルにして、次のようにして読み込むのが楽です：</p>

<pre class="cell">
with open('filename.txt') as f:
    text = f.read()
</pre>

<h2>Sudachiを使う</h2>

<p><code>pip install sudachipy sudachidict_core</code> でインストールできます。Pythonで使うほか、ターミナルでコマンド <code>sudachipy</code> も使えます：</p>

<pre>
% echo "すもももももももものうち" | sudachipy
すもも  名詞,普通名詞,一般,*,*,*        李
も      助詞,係助詞,*,*,*,*     も
もも    名詞,普通名詞,一般,*,*,*        もも
も      助詞,係助詞,*,*,*,*     も
もも    名詞,普通名詞,一般,*,*,*        もも
の      助詞,格助詞,*,*,*,*     の
うち    名詞,普通名詞,副詞可能,*,*,*    うち
EOS
</pre>

<p>Pythonから使うには次のようにします：</p>

<pre class="cell">
from sudachipy import dictionary

tokenizer_obj = dictionary.Dictionary().create()
morphemes = tokenizer_obj.tokenize("すもももももももものうち")
morphemes
</pre>

<pre>
&lt;MorphemeList[
  &lt;Morpheme(すもも, 0:3, (0, 77699))&gt;,
  &lt;Morpheme(も, 3:4, (0, 156944))&gt;,
  &lt;Morpheme(もも, 4:6, (0, 160209))&gt;,
  &lt;Morpheme(も, 6:7, (0, 156944))&gt;,
  &lt;Morpheme(もも, 7:9, (0, 160209))&gt;,
  &lt;Morpheme(の, 9:10, (0, 119137))&gt;,
  &lt;Morpheme(うち, 10:12, (0, 21763))&gt;,
]&gt;
</pre>

<pre class="cell">
[m.surface() for m in morphemes]
</pre>

<pre>
['すもも', 'も', 'もも', 'も', 'もも', 'の', 'うち']
</pre>

<pre class="cell">
" ".join([m.surface() for m in morphemes])
</pre>

<pre>
'すもも も もも も もも の うち'
</pre>

<pre class="cell">
[m.part_of_speech() for m in morphemes]
</pre>

<pre>
[('名詞', '普通名詞', '一般', '*', '*', '*'),
 ('助詞', '係助詞', '*', '*', '*', '*'),
 ('名詞', '普通名詞', '一般', '*', '*', '*'),
 ('助詞', '係助詞', '*', '*', '*', '*'),
 ('名詞', '普通名詞', '一般', '*', '*', '*'),
 ('助詞', '格助詞', '*', '*', '*', '*'),
 ('名詞', '普通名詞', '副詞可能', '*', '*', '*')]
</pre>

<pre class="cell">
[m.surface() for m in morphemes if m.part_of_speech()[0] == "名詞"]
</pre>

<pre>
['すもも', 'もも', 'もも', 'うち']
</pre>

<p>あとはMeCabと同様にできます。</p>

<h2>高校「情報」とワードクラウド</h2>

<p>ワードクラウド（タグクラウド）については、文科省の『高等学校学習指導要領（平成30年告示）解説 情報編』p.39 に次のように書かれています。</p>

<blockquote style="text-indent: 1em">
<p>更に、テキストマイニングの学習として、新聞記事や小説などをテキストデータとして読み込み、適当な整形等を行った上で、単語の出現頻度について調べさせ、出現頻度に応じた文字の大きさで単語を一覧表示したタグクラウドを作らせ、単語の重要度や他の単語との関係性を捉える学習活動などが考えられる。英語と日本語では、テキストマイニングをする際にどのような部分に違いがあるのかについて討論したり、実際にテキストマイニングを行って比較したりする活動なども考えられる。</p>
</blockquote>

<p>このため、<a href="https://textmining.userlocal.jp">AIテキストマイニング by ユーザーローカル</a>というサイトなどを使って実習している学校があります。</p>

<p>一方、テキストマイニングの専門家からはワードクラウドは評判が良くありません。例えば <a href="https://www.niemanlab.org/2011/10/word-clouds-considered-harmful/">Word clouds considered harmful</a> をご覧ください。</p>

<hr>

<footer>
<p><a href="../" rel="author">奥村 晴彦</a></p>
<p>Last modified: <time>2025-01-27 16:58:45 JST</time></p>
</footer>
</body>
</html>
