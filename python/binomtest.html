<!DOCTYPE html>
<html lang="ja">
<head>
<link rel="canonical" href="https://okumuralab.org/~okumura/python/binomtest.html">
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>2項検定</title>
<link rel="stylesheet" href="style.css">
<link rel="license" href="https://creativecommons.org/licenses/by/4.0/">
<script src="../js/load-mathjax.js" async></script>
</head>
<body>

<nav id="breadcrumbs">
<a href="../">ホーム</a> &gt;
<a href="./">Python</a> &gt;
</nav>

<h1>2項検定</h1>

<p>Rを使った<a href="../stat/tests_and_CI.html">検定と区間推定</a>もご参照ください。</p>

<h2>2項分布</h2>

<p>歪んだ硬貨があって、投げると確率 $\theta$ で<ruby>表<rp>（</rp><rt>おもて</rt><rp>）</rp></ruby>が出て、確率 $1 - \theta$ で裏が出るとします。この硬貨を $n$ 回投げて、表が $r$ 回出る確率を求めてください。</p>

<p>これが2項分布（<span lang="en">binomial distribution</span>）の問題です。答えは</p>

\[ _nC_r \theta^r (1-\theta)^{n-r} \]

<p>です。$_nC_r$ は $n$ 個から $r$ 個を選ぶ組合せ（<span lang="en">combination</span>）の数です。階乗（!）を使えば</p>

\[ _nC_r = \frac{n!}{r!(n-r)!} \]

<p>と表せます。</p>

<p>Python では、階乗は <code>math.factorial()</code> という関数ですので、例えば $_{10}C_3$ は次のようにして求められます。</p>

<pre class="cell">
import math

math.factorial(10) // (math.factorial(3) * math.factorial(7))
</pre>

<pre>
120
</pre>

<p>ここで <code>//</code> は整数の除算を意味します。</p>

<div class="note">
<p>上の計算は <code>math.factorial(10) / (math.factorial(3) * math.factorial(7))</code> でも同じですが、<code>//</code> を使えば結果は <code>120</code> なのに対し、<code>/</code> を使えば結果は <code>120.0</code> になります。つまり <code>/</code> は分子・分母が整数でも浮動小数点数に直してから除算します。Python はどんな大きな整数でも正確に計算できるのに対し、浮動小数点数は CPU で決まった精度でしか計算できません。例えば <code>math.factorial(200) // 10</code> は正確に計算できますが <code>math.factorial(200) / 10</code> は分子が大きすぎて浮動小数点数に直せないのでエラーになります。</p>
</div>

<div class="note">
<p>Python 3.8 以降では <code>math.comb(10, 3)</code> でも求められます。こちらのほうが高速です。ただ、Coogle Colaboratory がまだ Python 3.7 のようです。3.7 以前では次のようにして定義すると便利です。</p>
<pre>
def comb(n, r):
    return math.factorial(n) // (math.factorial(r) * math.factorial(n - r))
</pre>
</div>

<p>投げると確率 0.4 で表が出る硬貨を10回投げて表が3回出る確率 $_{10}C_3 \cdot 0.4^3 \cdot 0.6^7$ は</p>

<pre class="cell">
math.factorial(10) // (math.factorial(3) * math.factorial(7)) * 0.4**3 * 0.6**7
</pre>

<pre>
0.21499084799999998
</pre>

<p>です（正確な値は 0.214990848 です）。</p>

<p>同じ値は SciPy ライブラリを使っても求められます。SciPy ライブラリは非常に大きいので、統計の部分 <code>stats</code> だけインポートします。</p>

<pre class="cell">
from scipy import stats

stats.binom.pmf(3, 10, 0.4)
</pre>

<pre>
0.21499084799999982
</pre>

<p><code>stats.binom.pmf()</code> は <span lang="en">binomial probability mass function</span> の意味です。</p>

<p>投げると確率 0.5 で表が出る硬貨を10回投げて表が0〜10回出る確率を全部出力するには次のようにします。</p>

<pre class="cell">
stats.binom.pmf([0,1,2,3,4,5,6,7,8,9,10], 10, 0.5)
</pre>

<pre>
array([0.00097656, 0.00976563, 0.04394531, 0.1171875 , 0.20507812,
       0.24609375, 0.20507812, 0.1171875 , 0.04394531, 0.00976563,
       0.00097656])
</pre>

<p>0 以上 11 未満の整数 <code>[0,1,2,3,4,5,6,7,8,9,10]</code> は <code>range(11)</code> とも書けます。</p>

<p>これをグラフにするには次のように打ち込みます。</p>

<pre class="cell">
import matplotlib.pyplot as plt

plt.bar(range(11), stats.binom.pmf(range(11), 10, 0.5))
</pre>

<figure><img src="img/220715a.svg" alt="グラフ"></figure>

<p>確率なので、全部加えると 1 になります。</p>

<pre class="cell">
sum(stats.binom.pmf(range(11), 10, 0.5))
</pre>

<pre>
1.0000000000000004
</pre>

<p>ちなみに、<code>stats.binom.pmf()</code> の累積を求める <code>stats.binom.cdf()</code> という関数もあります。<code>cdf</code> は <span lang="en">cumulative distribution function</span> の意味です。</p>

<pre class="cell">
stats.binom.cdf(range(11), 10, 0.5)
</pre>

<pre>
array([9.76562500e-04, 1.07421875e-02, 5.46875000e-02, 1.71875000e-01,
       3.76953125e-01, 6.23046875e-01, 8.28125000e-01, 9.45312500e-01,
       9.89257812e-01, 9.99023438e-01, 1.00000000e+00])
</pre>

<h2>統計的検定の考え方</h2>

<div class="note">
<p>授業では<a href="../stat/binomp.html">JavaScriptのプログラム</a>も使って説明します。</p>
</div>

<p>硬貨を10回投げて表が2回しか出ませんでした。この硬貨は歪んでいるでしょうか。</p>

<p>ある母集団（ここでは例えばある高校の全生徒のように人数の多い集団を考えます）から10人をランダムに選んで聞いたところ、賛成2人、反対8人でした。母集団全体でも反対のほうが多いと言えるでしょうか。</p>

<p>これらの問いについて考えるために、仮に硬貨は歪んでいない（あるいは母集団全体では賛否が等しい）というモデル（帰無仮説、<span lang="en">null hypothesis</span>）を設定します。そして、この帰無仮説が正しかった場合に、実際に観測された事象、およびそれより珍しい事象の確率の合計を求めます。この場合は、表が0〜2回・8〜10回出る確率の合計です。この確率の合計を $p$ 値（ピーち、<span lang="en">$p$-value</span>）といいます。</p>

<p>$p$ 値が非常に小さければ、実際に起きた事象はこのモデルでは説明しにくいので、たぶん硬貨は歪んでいる（あるいは賛否は等しくない）と推測します。$p$ 値が大きければ、これだけのデータでは何も言えないので、判断を保留します（硬貨が歪んでない・賛否が等しいと推測するわけではありません）。</p>

<p>$p$ 値が大きいか小さいかの境界（有意水準）を仮に 0.05 として、$p \leqq 0.05$（または $p < 0.05$）であれば帰無仮説からの外れが「統計的に有意」（<span lang="en">statistically significant</span>）である、あるいは「帰無仮説は棄却（<span lang="en">reject</span>）される」ということがあります。0.05 という値に特に意味はありませんが、伝統的によく使われています（物理学では通常もっともっと厳しい条件を課します）。</p>

<p>さて、硬貨投げで表も裏も 1/2 の確率で出るという帰無仮説では、表が $r$ 回出る確率は $_{10}C_r (1/2)^{10}$ です。表が0、1、2、8、9、10回出る確率はそれぞれ</p>

<pre class="cell">
stats.binom.pmf([0,1,2,8,9,10], 10, 0.5)
</pre>

<pre>
array([0.00097656, 0.00976563, 0.04394531, 0.04394531, 0.00976563,
       0.00097656])
</pre>

<p>で、この合計、すなわち $p$ 値は</p>

<pre class="cell">
sum(stats.binom.pmf([0,1,2,8,9,10], 10, 0.5))
</pre>

<pre>
0.1093750000000001
</pre>

<p>になります。同じことが</p>

<pre class="cell">
stats.binom.cdf(2, 10, 0.5) * 2
</pre>

<pre>
0.109375
</pre>

<p>でも求められます。また、次のようにすれば、このような計算（2項検定）が簡単にできます。</p>

<pre class="cell">
stats.binomtest(2, 10, 0.5).pvalue
</pre>

<pre>
0.109375
</pre>

<div class="note">
<p>Python では SciPy に，$p$ 値を返すだけの古い <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.binom_test.html">scipy.stats.binom_test</a> と，2021-06-20 の <a href="https://scipy.github.io/devdocs/release.1.7.0.html">SciPy 1.7.0</a> で新しく追加された <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.binomtest.html">scipy.stats.binomtest</a> とがあります。計算量は，前者は $O(n)$，後者は2分探索を使うので $O(\log n)$ だそうです。古い方は次のように使います。</p>
<pre>  
stats.binom_test(2, 10, 0.5)
</pre>
<p><code>binom_test()</code> はSciPy 1.10.0の段階で「deprecated」で、1.12.0で削除される予定です。</p>
</div>

<p>つまり、表が2回出るという事象の $p$ 値は 0.1094 ほどです。したがって、有意水準を 0.05 とすれば、表裏の差は統計的に有意ではありませんし、アンケートであればこんなに少人数の結果から「賛成が少ない」という結論を導いてはいけないということになります。</p>

<p>表が1回（賛成が1人）なら、$p$ 値は 0.02 ほどになり、水準 0.05 で有意になります。</p>

<p>これが、フィッシャー（<span lang="en">R. A. Fisher</span>、1890〜1962年）が「有意性の検定」（<span lang="en">tests of significance, significance tests<span lang="en">）と呼んだ方法の考え方です。</p>

<div class="note">
<p>ここでは、実際に生じた事象またはそれより珍しい事象の生じる確率の合計として $p$ 値を定義しました。これは2項分布のような山の形の分布では両側の部分の確率になりますので、両側検定といいます。一方、片側だけを考える片側検定もあります。例えば表が2回出た場合の（左側だけの）片側 $p$ 値は、表が0回・1回・2回出る確率の合計です。</p>
  
<p>ICH（医薬品規制調和国際会議）の定める<a href="https://www.pmda.go.jp/int-activities/int-harmony/ich/0031.html">ICH E9</a>「臨床試験のための統計的原則」というガイドラインでは、「原則として片側仮説を検証する場合は2.5%、両側仮説の場合は5%とすること」とされています。</p>
</div>

<h2>区間推定</h2>

<div class="note">
<p>授業では<a href="../stat/binom.html">JavaScriptのプログラム</a>も使って説明します。</p>
<p>なお、高校「数学B」では、2項分布 $B(n, \theta)$ の平均が $n\theta$、分散が $n\theta(1-\theta)$ であることを使って、同じ平均と分散を持つ正規分布で近似して扱うことが多いと思います（中心極限定理から $n \to \infty$ で正規分布になります）。</p>
</div>

<p>10回投げて2回表が出たとき、表が出る確率の95%信頼区間は次のようにして求めます。これは正規分布近似ではなく <span lang="en">Clopper-Pearson</span> の正確な方法を使っています。</p>

<pre class="cell">
stats.binomtest(2, 10).proportion_ci()
</pre>

<pre>
ConfidenceInterval(low=0.025210726326833497, high=0.5560954623076415)
</pre>

<p>[0.025, 0.556] であることがわかります。</p>

<p>下限・上限を別々に求めるには次のようにします。</p>

<pre class="cell">
ci = stats.binomtest(2, 10).proportion_ci()
print(ci.low, ci.high)
</pre>

<pre>
0.025210726326833497 0.5560954623076415
</pre>

<div class="note">
<p>信頼区間は <a href="https://www.statsmodels.org/dev/generated/statsmodels.stats.proportion.proportion_confint.html">statsmodels.stats.proportion.proportion_confint</a> でも求められます：</p>
<pre class="cell">
from statsmodels.stats.proportion import proportion_confint

proportion_confint(2, 10, method="beta")
</pre>
<pre>
(0.02521072632683336, 0.5560954623076415)
</pre>
</div>

<h2>Rの <code>binom.test()</code> をPythonで実現</h2>

<p>Rには <code>binom.test()</code> という関数があります：</p>

<pre>
binom.test(x, n, p = 0.5,
           alternative = c("two.sided", "less", "greater"),
           conf.level = 0.95)
</pre>

<p>実行例：</p>

<pre>
&gt; binom.test(2, 10)

	Exact binomial test

data:  2 and 10
number of successes = 2, number of trials = 10, p-value = 0.1094
alternative hypothesis: true probability of success is not equal to 0.5
95 percent confidence interval:
 0.02521073 0.55609546
sample estimates:
probability of success 
                   0.2 
</pre>

<p>これとほぼ同じことをするPythonの関数を作ってみました。</p>

<pre class="cell">
from scipy import stats

def binom_test(x, n, p=0.5, alternative="two-sided", conf_level=0.95):
    r = stats.binomtest(x, n, p, alternative)
    print()
    print("	Exact binomial test")
    print()
    print(f"data:  {x} and {n}")
    print(f"number of successes = {x}, number of trials = {n}, p-value = {r.pvalue:.4g}")
    if alternative == "two-sided":
        s = "not equal to"
    else:
        s = alternative + " than"
    print(f"alternative hypothesis: true probability of success is {s} {p}")
    print(f"{conf_level * 100:g} percent confidence interval:")
    ci = r.proportion_ci(confidence_level=conf_level)
    print(f" {ci.low:.8f} {ci.high:.8f}")
    print("sample estimates:")
    print("probability of success ")
    print(f"                   {r.proportion_estimate:.4g} ")
</pre>

<p>実行例：</p>

<pre class="cell">
binom_test(2, 10)
</pre>

<pre>

	Exact binomial test

data:  2 and 10
number of successes = 2, number of trials = 10, p-value = 0.1094
alternative hypothesis: true probability of success is not equal to 0.5
95.0 percent confidence interval:
 0.02521073 0.55609546
sample estimates:
probability of success 
                   0.2 
</pre>

<hr>

<footer>
<p><a href="../" rel="author">奥村 晴彦</a></p>
<p>Last modified: <time>2023-06-07 09:25:34 JST</time></p>
</footer>
</body>
</html>
